{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3_Q2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtbIt4Wf+SPSP0i5KzRu4w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carloidangelo/ECSE-415/blob/main/A3_Q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBI6y87Zf-rW"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYZGbD43Br4m"
      },
      "source": [
        "##Image Classification with Convolution Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61n60d9RnV-c"
      },
      "source": [
        "# Download dataset (batch size = 32)\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vKiqKejsCc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2e7d01-e9cf-40d3-a571-4b33eb7c924d"
      },
      "source": [
        "# Implement CNN\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
        "        self.fc1 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = x.view(-1, 4096)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# run code on GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "net = Net()\n",
        "net = net.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j9HBIFF9w5u"
      },
      "source": [
        "# Create an instance of SGD optimizer with learning rate of 0.001\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "\n",
        "# Create an instance of categorical cross entropy criterion\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFdL1aHXVVWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50a5d3e-50c5-4627-8151-b32909dc9fad"
      },
      "source": [
        "# Train the CNN for 10 epochs\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 625 == 624:    # print every 625 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "          (epoch + 1, i + 1, running_loss / 625))\n",
        "      running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   625] loss: 2.288\n",
            "[1,  1250] loss: 2.219\n",
            "[1,  1875] loss: 1.282\n",
            "[2,   625] loss: 0.497\n",
            "[2,  1250] loss: 0.427\n",
            "[2,  1875] loss: 0.378\n",
            "[3,   625] loss: 0.365\n",
            "[3,  1250] loss: 0.344\n",
            "[3,  1875] loss: 0.337\n",
            "[4,   625] loss: 0.313\n",
            "[4,  1250] loss: 0.300\n",
            "[4,  1875] loss: 0.278\n",
            "[5,   625] loss: 0.264\n",
            "[5,  1250] loss: 0.245\n",
            "[5,  1875] loss: 0.230\n",
            "[6,   625] loss: 0.221\n",
            "[6,  1250] loss: 0.193\n",
            "[6,  1875] loss: 0.191\n",
            "[7,   625] loss: 0.179\n",
            "[7,  1250] loss: 0.168\n",
            "[7,  1875] loss: 0.155\n",
            "[8,   625] loss: 0.149\n",
            "[8,  1250] loss: 0.145\n",
            "[8,  1875] loss: 0.134\n",
            "[9,   625] loss: 0.132\n",
            "[9,  1250] loss: 0.123\n",
            "[9,  1875] loss: 0.117\n",
            "[10,   625] loss: 0.115\n",
            "[10,  1250] loss: 0.111\n",
            "[10,  1875] loss: 0.107\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qufUWYWRfVMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8321cb58-7f38-4416-9f6b-a342a7ac68c6"
      },
      "source": [
        "# Predict labels of the test images using the above trained CNN\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Display classification accuracy\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}